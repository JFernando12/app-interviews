[
  {
    "id": "python-1",
    "question": "What is the difference between a list and a tuple in Python?",
    "answer": "Lists and tuples are both sequence types in Python, but they have key differences:\n\n**Lists:**\n- Mutable (can be modified after creation)\n- Use square brackets []\n- Support item assignment, append, remove operations\n- Slightly slower due to mutability overhead\n\n**Tuples:**\n- Immutable (cannot be modified after creation)\n- Use parentheses ()\n- Cannot change elements after creation\n- Faster and more memory efficient\n- Can be used as dictionary keys (hashable)\n\n```python\n# List example\nmy_list = [1, 2, 3]\nmy_list[0] = 10  # Works\nmy_list.append(4)  # Works\nprint(my_list)  # [10, 2, 3, 4]\n\n# Tuple example\nmy_tuple = (1, 2, 3)\n# my_tuple[0] = 10  # TypeError: object doesn't support item assignment\nprint(my_tuple)  # (1, 2, 3)\n\n# Tuple as dictionary key\ncoordinates = {(0, 0): 'origin', (1, 1): 'point'}\n```",
    "context": "Basic Python data structures",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "beginner",
    "tags": ["data-structures", "lists", "tuples", "mutability"]
  },
  {
    "id": "python-2",
    "question": "Explain the difference between '==' and 'is' operators in Python.",
    "answer": "The == and is operators serve different purposes:\n\n**== (Equality operator):**\n- Compares the values of objects\n- Calls the __eq__ method\n- Returns True if values are equal\n\n**is (Identity operator):**\n- Compares the identity of objects (memory address)\n- Checks if both variables point to the same object\n- Uses id function internally\n\nThe difference is crucial: == checks if objects have the same value, while is checks if they are the same object in memory. Python caches small integers and some strings, so is might return True for small numbers but False for larger ones.\n\n```python\n# Example 1: Integers\na = 1000\nb = 1000\nprint(a == b)  # True (same value)\nprint(a is b)  # False (different objects in memory)\n\n# Example 2: Small integers (cached)\nc = 5\nd = 5\nprint(c == d)  # True (same value)\nprint(c is d)  # True (Python caches small integers -5 to 256)\n\n# Example 3: Lists\nlist1 = [1, 2, 3]\nlist2 = [1, 2, 3]\nlist3 = list1\n\nprint(list1 == list2)  # True (same values)\nprint(list1 is list2)  # False (different objects)\nprint(list1 is list3)  # True (same object)\n\n# Example 4: None comparison (always use 'is')\nvalue = None\nprint(value is None)  # Correct way\nprint(value == None)  # Works but not recommended\n```",
    "context": "Python operators and object comparison",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": ["operators", "comparison", "identity", "memory"]
  },
  {
    "id": "python-3",
    "question": "What are Python decorators and how do they work?",
    "answer": "Decorators are a powerful feature that allows you to modify or extend the behavior of functions or classes without permanently modifying their code. They use the @ syntax and are essentially functions that take another function as an argument.\n\n**How decorators work:**\n1. A decorator is a function that takes a function as input\n2. Returns a modified version of that function\n3. The @decorator_name syntax is syntactic sugar\n\n```python\n# Basic decorator example\ndef my_decorator(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Before calling {func.__name__}\")\n        result = func(*args, **kwargs)\n        print(f\"After calling {func.__name__}\")\n        return result\n    return wrapper\n\n# Using the decorator\n@my_decorator\ndef greet(name):\n    print(f\"Hello, {name}!\")\n\n# Equivalent to: greet = my_decorator(greet)\ngreet(\"Alice\")\n# Output:\n# Before calling greet\n# Hello, Alice!\n# After calling greet\n\n# Decorator with parameters\ndef repeat(times):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            for _ in range(times):\n                result = func(*args, **kwargs)\n            return result\n        return wrapper\n    return decorator\n\n@repeat(3)\ndef say_hello():\n    print(\"Hello!\")\n\nsay_hello()\n# Output:\n# Hello!\n# Hello!\n# Hello!\n\n# Built-in decorators\nclass MyClass:\n    @staticmethod\n    def static_method():\n        return \"This is a static method\"\n    \n    @classmethod\n    def class_method(cls):\n        return f\"This is a class method of {cls.__name__}\"\n    \n    @property\n    def my_property(self):\n        return \"This is a property\"\n```",
    "context": "Python advanced features and design patterns",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": ["decorators", "functions", "design-patterns", "metaprogramming"]
  },
  {
    "id": "python-4",
    "question": "Explain Python's Global Interpreter Lock (GIL). What are its implications?",
    "answer": "The Global Interpreter Lock (GIL) is a mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes simultaneously in a single process.\n\n**Key points about GIL:**\n- Only one thread can execute Python code at a time\n- Prevents race conditions with Python object reference counting\n- Makes single-threaded programs faster\n- Limits multi-threading effectiveness for CPU-bound tasks\n\n**Implications:**\n\n```python\nimport threading\nimport time\n\n# CPU-bound task (limited by GIL)\ndef cpu_bound_task(n):\n    result = 0\n    for i in range(n):\n        result += i * i\n    return result\n\n# Threading won't help much for CPU-bound tasks\nstart_time = time.time()\nthreads = []\nfor _ in range(4):\n    thread = threading.Thread(target=cpu_bound_task, args=(1000000,))\n    threads.append(thread)\n    thread.start()\n\nfor thread in threads:\n    thread.join()\n\nprint(f\"Multi-threaded time: {time.time() - start_time:.2f}s\")\n\n# I/O-bound task (GIL released during I/O)\nimport requests\n\ndef io_bound_task(url):\n    response = requests.get(url)\n    return response.status_code\n\n# Threading helps with I/O-bound tasks\nurls = ['http://httpbin.org/delay/1'] * 4\nstart_time = time.time()\nthreads = []\nfor url in urls:\n    thread = threading.Thread(target=io_bound_task, args=(url,))\n    threads.append(thread)\n    thread.start()\n\nfor thread in threads:\n    thread.join()\n\nprint(f\"I/O-bound time: {time.time() - start_time:.2f}s\")\n\n# Solutions to GIL limitations:\n\n# 1. Multiprocessing for CPU-bound tasks\nfrom multiprocessing import Pool\n\ndef parallel_cpu_task():\n    with Pool(processes=4) as pool:\n        results = pool.map(cpu_bound_task, [1000000] * 4)\n    return results\n\n# 2. asyncio for I/O-bound tasks\nimport asyncio\nimport aiohttp\n\nasync def async_io_task(session, url):\n    async with session.get(url) as response:\n        return response.status\n\nasync def main():\n    async with aiohttp.ClientSession() as session:\n        tasks = [async_io_task(session, url) for url in urls]\n        results = await asyncio.gather(*tasks)\n    return results\n```",
    "context": "Python internals and concurrency",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "advanced",
    "tags": [
      "GIL",
      "threading",
      "concurrency",
      "performance",
      "multiprocessing"
    ]
  },
  {
    "id": "python-5",
    "question": "What are Python generators and how do they differ from regular functions?",
    "answer": "Generators are special functions that return an iterator object and produce values on-demand using the yield keyword. They provide memory-efficient iteration over large datasets.\n\n**Key differences from regular functions:**\n- Use yield instead of return\n- Maintain state between calls\n- Return a generator object (iterator)\n- Lazy evaluation (values computed when needed)\n- Memory efficient for large datasets\n\n```python\n# Regular function vs Generator\n\n# Regular function - creates entire list in memory\ndef create_squares_list(n):\n    result = []\n    for i in range(n):\n        result.append(i * i)\n    return result\n\n# Generator function - yields values one at a time\ndef create_squares_generator(n):\n    for i in range(n):\n        yield i * i\n\n# Usage comparison\nprint(\"Regular function:\")\nsquares_list = create_squares_list(5)\nprint(type(squares_list))  # <class 'list'>\nprint(squares_list)  # [0, 1, 4, 9, 16]\n\nprint(\"\\nGenerator function:\")\nsquares_gen = create_squares_generator(5)\nprint(type(squares_gen))  # <class 'generator'>\nprint(list(squares_gen))  # [0, 1, 4, 9, 16]\n\n# Generator maintains state\ndef countdown(n):\n    print(f\"Starting countdown from {n}\")\n    while n > 0:\n        yield n\n        n -= 1\n    print(\"Countdown finished!\")\n\n# Using the generator\ncounter = countdown(3)\nprint(next(counter))  # Starting countdown from 3, then 3\nprint(next(counter))  # 2\nprint(next(counter))  # 1\n# print(next(counter))  # Countdown finished!, then StopIteration\n\n# Generator expressions (similar to list comprehensions)\nsquares_gen_expr = (x * x for x in range(5))\nprint(list(squares_gen_expr))  # [0, 1, 4, 9, 16]\n\n# Memory efficiency example\nimport sys\n\n# List comprehension\nsquares_list = [x * x for x in range(1000)]\nprint(f\"List size: {sys.getsizeof(squares_list)} bytes\")\n\n# Generator expression\nsquares_gen = (x * x for x in range(1000))\nprint(f\"Generator size: {sys.getsizeof(squares_gen)} bytes\")\n\n# Practical example: Reading large files\ndef read_large_file(file_path):\n    \"\"\"Generator for reading large files line by line\"\"\"\n    with open(file_path, 'r') as file:\n        for line in file:\n            yield line.strip()\n\n# Usage: processes one line at a time, not entire file\n# for line in read_large_file('large_file.txt'):\n#     process(line)\n\n# Generator delegation with yield from\ndef sub_generator():\n    yield 1\n    yield 2\n    yield 3\n\ndef main_generator():\n    yield 'start'\n    yield from sub_generator()  # Delegates to sub_generator\n    yield 'end'\n\nprint(list(main_generator()))  # ['start', 1, 2, 3, 'end']\n```",
    "context": "Python iterators and memory management",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": [
      "generators",
      "iterators",
      "yield",
      "memory-efficiency",
      "lazy-evaluation"
    ]
  },
  {
    "id": "python-6",
    "question": "Explain the difference between *args and **kwargs in Python.",
    "answer": "*args and **kwargs are used to handle variable-length arguments in Python functions, allowing functions to accept any number of positional and keyword arguments.\n\n***args (Variable Positional Arguments):**\n- Collects extra positional arguments into a tuple\n- The name 'args' is conventional, you can use any name\n- The * is what makes it special\n\n****kwargs (Variable Keyword Arguments):**\n- Collects extra keyword arguments into a dictionary\n- The name 'kwargs' is conventional\n- The ** is what makes it special\n\n```python\n# Basic usage of *args\ndef sum_all(*args):\n    print(f\"args type: {type(args)}\")  # <class 'tuple'>\n    print(f\"args value: {args}\")\n    return sum(args)\n\nprint(sum_all(1, 2, 3, 4, 5))  # args: (1, 2, 3, 4, 5), result: 15\nprint(sum_all(10, 20))         # args: (10, 20), result: 30\n\n# Basic usage of **kwargs\ndef print_info(**kwargs):\n    print(f\"kwargs type: {type(kwargs)}\")  # <class 'dict'>\n    print(f\"kwargs value: {kwargs}\")\n    for key, value in kwargs.items():\n        print(f\"{key}: {value}\")\n\nprint_info(name=\"Alice\", age=30, city=\"New York\")\n# kwargs: {'name': 'Alice', 'age': 30, 'city': 'New York'}\n\n# Using both *args and **kwargs\ndef flexible_function(required_arg, *args, **kwargs):\n    print(f\"Required: {required_arg}\")\n    print(f\"Extra positional args: {args}\")\n    print(f\"Extra keyword args: {kwargs}\")\n\nflexible_function(\"Hello\", 1, 2, 3, name=\"Bob\", age=25)\n# Required: Hello\n# Extra positional args: (1, 2, 3)\n# Extra keyword args: {'name': 'Bob', 'age': 25}\n\n# Function call unpacking\ndef greet(first, last, age):\n    return f\"Hello {first} {last}, you are {age} years old\"\n\n# Unpacking with *\nnames = [\"John\", \"Doe\", 30]\nprint(greet(*names))  # Hello John Doe, you are 30 years old\n\n# Unpacking with **\nperson = {\"first\": \"Jane\", \"last\": \"Smith\", \"age\": 25}\nprint(greet(**person))  # Hello Jane Smith, you are 25 years old\n\n# Practical example: Decorator that preserves function signature\ndef logger(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n        result = func(*args, **kwargs)\n        print(f\"{func.__name__} returned {result}\")\n        return result\n    return wrapper\n\n@logger\ndef add(a, b):\n    return a + b\n\n@logger\ndef greet_person(name, greeting=\"Hello\"):\n    return f\"{greeting}, {name}!\"\n\nprint(add(3, 5))\nprint(greet_person(\"Alice\", greeting=\"Hi\"))\n\n# Order matters: positional, *args, keyword-only, **kwargs\ndef complex_function(pos1, pos2, *args, keyword_only, default=\"default\", **kwargs):\n    print(f\"pos1: {pos1}\")\n    print(f\"pos2: {pos2}\")\n    print(f\"args: {args}\")\n    print(f\"keyword_only: {keyword_only}\")\n    print(f\"default: {default}\")\n    print(f\"kwargs: {kwargs}\")\n\n# Must provide keyword_only as keyword argument\ncomplex_function(1, 2, 3, 4, keyword_only=\"required\", extra=\"value\")\n```",
    "context": "Python function parameters and argument handling",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": ["functions", "arguments", "args", "kwargs", "unpacking"]
  },
  {
    "id": "python-7",
    "question": "What are Python context managers and how do you implement them?",
    "answer": "Context managers are objects that define methods to be used with the with statement. They ensure proper setup and cleanup of resources, even if exceptions occur.\n\n**Context Manager Protocol:**\n- __enter__(): Called when entering the with block\n- __exit__(): Called when exiting the with block (even on exceptions)\n\n**Implementation methods:**\n1. Class-based (implementing __enter__ and __exit__)\n2. Function-based using @contextmanager decorator\n\n```python\n# Method 1: Class-based context manager\nclass FileManager:\n    def __init__(self, filename, mode):\n        self.filename = filename\n        self.mode = mode\n        self.file = None\n    \n    def __enter__(self):\n        print(f\"Opening file {self.filename}\")\n        self.file = open(self.filename, self.mode)\n        return self.file\n    \n    def __exit__(self, exc_type, exc_value, traceback):\n        print(f\"Closing file {self.filename}\")\n        if self.file:\n            self.file.close()\n        \n        # Handle exceptions\n        if exc_type is not None:\n            print(f\"Exception occurred: {exc_type.__name__}: {exc_value}\")\n        \n        # Return False to propagate exceptions, True to suppress them\n        return False\n\n# Usage\nwith FileManager('test.txt', 'w') as f:\n    f.write('Hello, World!')\n# Automatically closes file even if exception occurs\n\n# Method 2: Function-based with @contextmanager decorator\nfrom contextlib import contextmanager\nimport time\n\n@contextmanager\ndef timer():\n    start_time = time.time()\n    print(\"Timer started\")\n    try:\n        yield start_time  # Value returned to 'as' variable\n    finally:\n        end_time = time.time()\n        print(f\"Timer ended. Elapsed: {end_time - start_time:.2f}s\")\n\n# Usage\nwith timer() as start:\n    time.sleep(1)\n    print(f\"Started at: {start}\")\n\n# Database connection context manager\n@contextmanager\ndef database_connection(db_url):\n    print(f\"Connecting to {db_url}\")\n    connection = None\n    try:\n        # Simulate database connection\n        connection = f\"Connection to {db_url}\"\n        yield connection\n    except Exception as e:\n        print(f\"Error: {e}\")\n        if connection:\n            print(\"Rolling back transaction\")\n        raise\n    finally:\n        if connection:\n            print(\"Closing database connection\")\n\nwith database_connection(\"postgresql://localhost/mydb\") as conn:\n    print(f\"Using {conn}\")\n    # Simulate database operations\n\n# Multiple context managers\nwith FileManager('input.txt', 'r') as infile, \\\n     FileManager('output.txt', 'w') as outfile:\n    content = infile.read()\n    outfile.write(content.upper())\n\n# Built-in context managers examples\nimport threading\nimport tempfile\nimport os\n\n# Lock context manager\nlock = threading.Lock()\nwith lock:\n    print(\"Critical section\")\n    # Lock automatically released\n\n# Temporary directory\nwith tempfile.TemporaryDirectory() as temp_dir:\n    print(f\"Temporary directory: {temp_dir}\")\n    # Create files in temp_dir\n    with open(os.path.join(temp_dir, 'temp_file.txt'), 'w') as f:\n        f.write('Temporary content')\n# Directory and all contents automatically deleted\n\n# Error handling in context managers\n@contextmanager\ndef error_handler():\n    try:\n        print(\"Entering context\")\n        yield\n    except ValueError as e:\n        print(f\"Handled ValueError: {e}\")\n        # Return True to suppress the exception\n        return True\n    except Exception as e:\n        print(f\"Unhandled exception: {e}\")\n        raise  # Re-raise other exceptions\n    finally:\n        print(\"Cleanup code\")\n\nwith error_handler():\n    raise ValueError(\"This will be handled\")\n\nprint(\"Execution continues...\")\n\n# Nested context managers with contextlib.ExitStack\nfrom contextlib import ExitStack\n\nfilenames = ['file1.txt', 'file2.txt', 'file3.txt']\nwith ExitStack() as stack:\n    files = [stack.enter_context(open(fname, 'w')) for fname in filenames]\n    for i, f in enumerate(files):\n        f.write(f'Content for file {i+1}')\n# All files automatically closed\n```",
    "context": "Python resource management and cleanup patterns",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": [
      "context-managers",
      "with-statement",
      "resource-management",
      "cleanup",
      "decorators"
    ]
  },
  {
    "id": "python-8",
    "question": "Explain Python's memory management and garbage collection.",
    "answer": "Python uses automatic memory management with reference counting as the primary mechanism, supplemented by a cyclic garbage collector for handling circular references.\n\n**Key Components:**\n1. **Reference Counting**: Tracks how many references point to an object\n2. **Garbage Collector**: Handles circular references\n3. **Memory Pools**: Optimizes allocation for small objects\n4. **Object Interning**: Reuses immutable objects\n\n```python\nimport sys\nimport gc\nimport weakref\n\n# Reference counting demonstration\nclass MyClass:\n    def __init__(self, name):\n        self.name = name\n    \n    def __del__(self):\n        print(f\"Object {self.name} is being destroyed\")\n\n# Creating and tracking references\nobj = MyClass(\"Object1\")\nprint(f\"Reference count: {sys.getrefcount(obj)}\")  # Usually 2 (obj + getrefcount parameter)\n\n# Adding more references\nobj_ref1 = obj\nobj_ref2 = obj\nprint(f\"Reference count: {sys.getrefcount(obj)}\")  # Increased\n\n# Removing references\ndel obj_ref1\ndel obj_ref2\nprint(f\"Reference count: {sys.getrefcount(obj)}\")\n\ndel obj  # Object destroyed here due to reference count reaching 0\n\n# Circular reference problem\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.children = []\n        self.parent = None\n    \n    def add_child(self, child):\n        child.parent = self  # Creates circular reference\n        self.children.append(child)\n    \n    def __del__(self):\n        print(f\"Node {self.value} destroyed\")\n\n# Creating circular references\nroot = Node(\"root\")\nchild = Node(\"child\")\nroot.add_child(child)\n\nprint(f\"Root references: {sys.getrefcount(root)}\")\nprint(f\"Child references: {sys.getrefcount(child)}\")\n\n# Delete references but objects won't be destroyed immediately\n# due to circular reference\ndel root\ndel child\n\n# Force garbage collection\nprint(\"Before garbage collection:\")\nprint(f\"Objects before GC: {len(gc.get_objects())}\")\n\ncollected = gc.collect()\nprint(f\"Collected {collected} objects\")\nprint(f\"Objects after GC: {len(gc.get_objects())}\")\n\n# Weak references to avoid circular references\nclass WeakNode:\n    def __init__(self, value):\n        self.value = value\n        self.children = []\n        self._parent = None\n    \n    @property\n    def parent(self):\n        return self._parent() if self._parent else None\n    \n    @parent.setter\n    def parent(self, value):\n        self._parent = weakref.ref(value) if value else None\n    \n    def add_child(self, child):\n        child.parent = self\n        self.children.append(child)\n    \n    def __del__(self):\n        print(f\"WeakNode {self.value} destroyed\")\n\n# Using weak references\nweak_root = WeakNode(\"weak_root\")\nweak_child = WeakNode(\"weak_child\")\nweak_root.add_child(weak_child)\n\ndel weak_root  # Now properly destroyed\ndel weak_child\n\n# Memory profiling and optimization\ndef memory_usage_demo():\n    # Small integer caching\n    a = 100\n    b = 100\n    print(f\"Small integers cached: {a is b}\")  # True\n    \n    c = 1000\n    d = 1000\n    print(f\"Large integers cached: {c is d}\")  # False\n    \n    # String interning\n    s1 = \"hello\"\n    s2 = \"hello\"\n    print(f\"String literals interned: {s1 is s2}\")  # True\n    \n    s3 = \"hello world\"\n    s4 = \"hello world\"\n    print(f\"Longer strings interned: {s3 is s4}\")  # May be False\n    \n    # Force string interning\n    import sys\n    s5 = sys.intern(\"custom string\")\n    s6 = sys.intern(\"custom string\")\n    print(f\"Force interned strings: {s5 is s6}\")  # True\n\nmemory_usage_demo()\n\n# Garbage collection configuration\nprint(\"\\nGarbage Collection Info:\")\nprint(f\"GC thresholds: {gc.get_threshold()}\")\nprint(f\"GC counts: {gc.get_count()}\")\nprint(f\"GC stats: {gc.get_stats()}\")\n\n# Disable/enable garbage collection\ngc.disable()\nprint(f\"GC enabled: {gc.isenabled()}\")\ngc.enable()\nprint(f\"GC enabled: {gc.isenabled()}\")\n\n# Memory-efficient programming tips\ndef memory_efficient_tips():\n    # Use generators instead of lists for large datasets\n    def large_range_generator(n):\n        for i in range(n):\n            yield i ** 2\n    \n    # Use __slots__ to reduce memory overhead\n    class EfficientClass:\n        __slots__ = ['x', 'y']  # Prevents dynamic attribute creation\n        \n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    class RegularClass:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n    \n    # Compare memory usage\n    efficient_obj = EfficientClass(1, 2)\n    regular_obj = RegularClass(1, 2)\n    \n    print(f\"Efficient class size: {sys.getsizeof(efficient_obj)}\")\n    print(f\"Regular class size: {sys.getsizeof(regular_obj)}\")\n    \n    # Use collections.deque for efficient append/pop operations\n    from collections import deque\n    \n    # Efficient queue operations\n    queue = deque()\n    queue.append(1)  # O(1)\n    queue.appendleft(0)  # O(1)\n    queue.pop()  # O(1)\n    queue.popleft()  # O(1)\n\nmemory_efficient_tips()\n\n# Debugging memory leaks\ndef find_memory_leaks():\n    # Track object creation\n    import tracemalloc\n    \n    tracemalloc.start()\n    \n    # Create some objects\n    data = [i for i in range(10000)]\n    \n    # Get current memory usage\n    current, peak = tracemalloc.get_traced_memory()\n    print(f\"Current memory usage: {current / 1024 / 1024:.1f} MB\")\n    print(f\"Peak memory usage: {peak / 1024 / 1024:.1f} MB\")\n    \n    tracemalloc.stop()\n\nfind_memory_leaks()\n```",
    "context": "Python internals and performance optimization",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "advanced",
    "tags": [
      "memory-management",
      "garbage-collection",
      "reference-counting",
      "performance",
      "optimization"
    ]
  },
  {
    "id": "python-9",
    "question": "What is the difference between deep copy and shallow copy in Python?",
    "answer": "Shallow copy and deep copy are two ways to copy objects in Python, differing in how they handle nested objects.\n\n**Shallow Copy:**\n- Creates a new object but inserts references to objects found in the original\n- Only copies the top-level object\n- Nested objects are shared between original and copy\n\n**Deep Copy:**\n- Creates a new object and recursively copies all nested objects\n- Creates completely independent copy\n- Changes to nested objects don't affect the original\n\n```python\nimport copy\n\n# Example with nested lists\noriginal = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n# Shallow copy methods\nshallow_copy1 = original.copy()              # Using .copy() method\nshallow_copy2 = original[:]                  # Using slice notation\nshallow_copy3 = list(original)              # Using constructor\nshallow_copy4 = copy.copy(original)         # Using copy module\n\n# Deep copy\ndeep_copy = copy.deepcopy(original)\n\nprint(\"Original:\", original)\nprint(\"Shallow copy:\", shallow_copy1)\nprint(\"Deep copy:\", deep_copy)\n\n# Check if they are the same object\nprint(f\"\\nSame object (original vs shallow): {original is shallow_copy1}\")  # False\nprint(f\"Same object (original vs deep): {original is deep_copy}\")        # False\n\n# Check if nested objects are the same\nprint(f\"\\nNested objects (original vs shallow): {original[0] is shallow_copy1[0]}\")  # True\nprint(f\"Nested objects (original vs deep): {original[0] is deep_copy[0]}\")        # False\n\n# Modify nested object in original\noriginal[0][0] = 'CHANGED'\n\nprint(\"\\nAfter modifying original[0][0]:\")\nprint(\"Original:\", original)           # [['CHANGED', 2, 3], [4, 5, 6], [7, 8, 9]]\nprint(\"Shallow copy:\", shallow_copy1)  # [['CHANGED', 2, 3], [4, 5, 6], [7, 8, 9]] - AFFECTED!\nprint(\"Deep copy:\", deep_copy)         # [[1, 2, 3], [4, 5, 6], [7, 8, 9]] - NOT affected\n\n# Example with custom objects\nclass Person:\n    def __init__(self, name, age, hobbies):\n        self.name = name\n        self.age = age\n        self.hobbies = hobbies  # This is a list (mutable)\n    \n    def __repr__(self):\n        return f\"Person('{self.name}', {self.age}, {self.hobbies})\"\n\n# Create original person\noriginal_person = Person(\"Alice\", 30, [\"reading\", \"swimming\"])\n\n# Create copies\nshallow_person = copy.copy(original_person)\ndeep_person = copy.deepcopy(original_person)\n\nprint(\"\\nPerson Objects:\")\nprint(\"Original:\", original_person)\nprint(\"Shallow:\", shallow_person)\nprint(\"Deep:\", deep_person)\n\n# Check object identity\nprint(f\"\\nSame person object (original vs shallow): {original_person is shallow_person}\")  # False\nprint(f\"Same hobbies list (original vs shallow): {original_person.hobbies is shallow_person.hobbies}\")  # True\nprint(f\"Same hobbies list (original vs deep): {original_person.hobbies is deep_person.hobbies}\")  # False\n\n# Modify hobbies\noriginal_person.hobbies.append(\"cycling\")\noriginal_person.age = 31\n\nprint(\"\\nAfter modifying original person:\")\nprint(\"Original:\", original_person)  # Age and hobbies changed\nprint(\"Shallow:\", shallow_person)   # Only hobbies changed (shared list)\nprint(\"Deep:\", deep_person)         # No changes (completely independent)\n\n# Performance comparison\nimport time\n\n# Large nested structure\nlarge_data = [[i + j for j in range(100)] for i in range(100)]\n\n# Time shallow copy\nstart = time.time()\nfor _ in range(1000):\n    copy.copy(large_data)\nshallow_time = time.time() - start\n\n# Time deep copy\nstart = time.time()\nfor _ in range(1000):\n    copy.deepcopy(large_data)\ndeep_time = time.time() - start\n\nprint(f\"\\nPerformance (1000 iterations):\")\nprint(f\"Shallow copy: {shallow_time:.4f}s\")\nprint(f\"Deep copy: {deep_time:.4f}s\")\nprint(f\"Deep copy is {deep_time/shallow_time:.1f}x slower\")\n\n# Special cases and considerations\n\n# 1. Immutable objects - shallow copy is sufficient\nimmutable_data = (1, 2, (3, 4))\nshallow_immutable = copy.copy(immutable_data)\ndeep_immutable = copy.deepcopy(immutable_data)\n\n# For immutable objects, both copies behave the same\nprint(f\"\\nImmutable shallow copy same: {immutable_data is shallow_immutable}\")  # True (optimization)\nprint(f\"Immutable deep copy same: {immutable_data is deep_immutable}\")      # True (optimization)\n\n# 2. Circular references\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.ref = None\n    \n    def __repr__(self):\n        return f\"Node({self.value})\"\n\n# Create circular reference\nnode1 = Node(1)\nnode2 = Node(2)\nnode1.ref = node2\nnode2.ref = node1\n\n# Deep copy handles circular references\ntry:\n    deep_node = copy.deepcopy(node1)\n    print(f\"\\nDeep copy with circular reference successful: {deep_node}\")\n    print(f\"Circular reference preserved: {deep_node.ref.ref is deep_node}\")\nexcept Exception as e:\n    print(f\"Error with circular reference: {e}\")\n\n# 3. Custom copy behavior\nclass CustomCopy:\n    def __init__(self, data):\n        self.data = data\n    \n    def __copy__(self):\n        print(\"Custom shallow copy called\")\n        return CustomCopy(self.data)\n    \n    def __deepcopy__(self, memo):\n        print(\"Custom deep copy called\")\n        return CustomCopy(copy.deepcopy(self.data, memo))\n    \n    def __repr__(self):\n        return f\"CustomCopy({self.data})\"\n\ncustom_obj = CustomCopy([1, 2, 3])\nshallow_custom = copy.copy(custom_obj)\ndeep_custom = copy.deepcopy(custom_obj)\n```",
    "context": "Python object copying and memory management",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": [
      "copy",
      "shallow-copy",
      "deep-copy",
      "objects",
      "memory",
      "mutability"
    ]
  },
  {
    "id": "python-10",
    "question": "Explain Python's duck typing and how it relates to polymorphism.",
    "answer": "Duck typing is a concept in Python where the type or class of an object is less important than the methods it defines. The name comes from the phrase: \"If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.\"\n\n**Key Principles:**\n- Objects are considered compatible if they implement the required methods\n- No need for explicit inheritance or interface declarations\n- Runtime checking of method availability\n- Promotes flexibility and code reusability\n\n```python\n# Duck typing example - different classes with same interface\nclass Duck:\n    def fly(self):\n        return \"Duck flying\"\n    \n    def quack(self):\n        return \"Quack! Quack!\"\n\nclass Airplane:\n    def fly(self):\n        return \"Airplane flying\"\n    \n    def quack(self):\n        return \"Airplane cannot quack, but has the method\"\n\nclass Penguin:\n    def quack(self):\n        return \"Penguin making noise\"\n    \n    # Note: No fly method\n\n# Function that uses duck typing\ndef make_it_fly_and_quack(thing):\n    try:\n        print(thing.fly())\n        print(thing.quack())\n    except AttributeError as e:\n        print(f\"Error: {e}\")\n\n# All these work despite being different types\nduck = Duck()\nairplane = Airplane()\npenguin = Penguin()\n\nprint(\"Duck:\")\nmake_it_fly_and_quack(duck)\n\nprint(\"\\nAirplane:\")\nmake_it_fly_and_quack(airplane)\n\nprint(\"\\nPenguin:\")\nmake_it_fly_and_quack(penguin)  # Will raise AttributeError for fly()\n\n# File-like objects example\nclass StringFile:\n    def __init__(self, content):\n        self.content = content\n        self.position = 0\n    \n    def read(self, size=-1):\n        if size == -1:\n            result = self.content[self.position:]\n            self.position = len(self.content)\n        else:\n            result = self.content[self.position:self.position + size]\n            self.position += len(result)\n        return result\n    \n    def readline(self):\n        start = self.position\n        end = self.content.find('\\n', start)\n        if end == -1:\n            end = len(self.content)\n        else:\n            end += 1\n        result = self.content[start:end]\n        self.position = end\n        return result\n    \n    def close(self):\n        pass\n\n# Function that works with any file-like object\ndef process_file(file_obj):\n    \"\"\"Works with real files, StringIO, or our custom StringFile\"\"\"\n    content = file_obj.read()\n    print(f\"Read {len(content)} characters\")\n    return content\n\n# Works with different file-like objects\nfrom io import StringIO\n\n# Real file-like object from io module\nstring_io = StringIO(\"Hello from StringIO\")\nresult1 = process_file(string_io)\n\n# Our custom file-like object\ncustom_file = StringFile(\"Hello from custom file\")\nresult2 = process_file(custom_file)\n\nprint(f\"StringIO result: {result1}\")\nprint(f\"Custom file result: {result2}\")\n\n# Polymorphism with duck typing\nclass Shape:\n    \"\"\"Abstract base - not enforced by Python\"\"\"\n    def area(self):\n        raise NotImplementedError(\"Subclasses must implement area()\")\n    \n    def perimeter(self):\n        raise NotImplementedError(\"Subclasses must implement perimeter()\")\n\nclass Rectangle:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n    \n    def area(self):\n        return self.width * self.height\n    \n    def perimeter(self):\n        return 2 * (self.width + self.height)\n\nclass Circle:\n    def __init__(self, radius):\n        self.radius = radius\n    \n    def area(self):\n        return 3.14159 * self.radius ** 2\n    \n    def perimeter(self):\n        return 2 * 3.14159 * self.radius\n\nclass Triangle:\n    def __init__(self, a, b, c):\n        self.a = a\n        self.b = b\n        self.c = c\n    \n    def area(self):\n        # Heron's formula\n        s = (self.a + self.b + self.c) / 2\n        return (s * (s - self.a) * (s - self.b) * (s - self.c)) ** 0.5\n    \n    def perimeter(self):\n        return self.a + self.b + self.c\n\n# Function that works with any shape-like object\ndef print_shape_info(shape):\n    print(f\"Area: {shape.area():.2f}\")\n    print(f\"Perimeter: {shape.perimeter():.2f}\")\n\n# Works with all shape objects\nshapes = [\n    Rectangle(5, 3),\n    Circle(4),\n    Triangle(3, 4, 5)\n]\n\nfor i, shape in enumerate(shapes):\n    print(f\"\\nShape {i + 1}:\")\n    print_shape_info(shape)\n\n# Protocol-based programming (Python 3.8+)\nfrom typing import Protocol\n\nclass Drawable(Protocol):\n    \"\"\"Protocol defining what it means to be drawable\"\"\"\n    def draw(self) -> str:\n        ...\n\nclass Square:\n    def __init__(self, size):\n        self.size = size\n    \n    def draw(self):\n        return f\"Drawing a square of size {self.size}\"\n\nclass Star:\n    def __init__(self, points):\n        self.points = points\n    \n    def draw(self):\n        return f\"Drawing a star with {self.points} points\"\n\n# Function using protocol\ndef render_object(obj: Drawable) -> str:\n    return obj.draw()\n\n# Both objects satisfy the Drawable protocol\nsquare = Square(10)\nstar = Star(5)\n\nprint(f\"\\n{render_object(square)}\")\nprint(f\"{render_object(star)}\")\n\n# EAFP vs LBYL programming styles\n# EAFP: Easier to Ask for Forgiveness than Permission\n# LBYL: Look Before You Leap\n\ndef eafp_approach(obj):\n    \"\"\"Duck typing with EAFP\"\"\"\n    try:\n        return obj.some_method()\n    except AttributeError:\n        return \"Object doesn't have some_method\"\n\ndef lbyl_approach(obj):\n    \"\"\"Check before calling\"\"\"\n    if hasattr(obj, 'some_method'):\n        return obj.some_method()\n    else:\n        return \"Object doesn't have some_method\"\n\nclass HasMethod:\n    def some_method(self):\n        return \"Method called successfully\"\n\nclass NoMethod:\n    pass\n\n# Both approaches work, but EAFP is more Pythonic\nobj1 = HasMethod()\nobj2 = NoMethod()\n\nprint(f\"\\nEAFP with method: {eafp_approach(obj1)}\")\nprint(f\"EAFP without method: {eafp_approach(obj2)}\")\nprint(f\"LBYL with method: {lbyl_approach(obj1)}\")\nprint(f\"LBYL without method: {lbyl_approach(obj2)}\")\n\n# Duck typing with magic methods\nclass Vector:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    def __add__(self, other):\n        return Vector(self.x + other.x, self.y + other.y)\n    \n    def __str__(self):\n        return f\"Vector({self.x}, {self.y})\"\n    \n    def __len__(self):\n        return int((self.x ** 2 + self.y ** 2) ** 0.5)\n\nclass Point:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    def __add__(self, other):\n        return Point(self.x + other.x, self.y + other.y)\n    \n    def __str__(self):\n        return f\"Point({self.x}, {self.y})\"\n\n# Function that works with any object supporting + and str()\ndef combine_and_display(obj1, obj2):\n    result = obj1 + obj2\n    return str(result)\n\nvec1 = Vector(1, 2)\nvec2 = Vector(3, 4)\npoint1 = Point(1, 2)\npoint2 = Point(3, 4)\n\nprint(f\"\\nVector combination: {combine_and_display(vec1, vec2)}\")\nprint(f\"Point combination: {combine_and_display(point1, point2)}\")\n```",
    "context": "Python type system and design patterns",
    "type": "TECHNICAL",
    "programming_language": "python",
    "difficulty": "intermediate",
    "tags": [
      "duck-typing",
      "polymorphism",
      "protocols",
      "type-system",
      "design-patterns"
    ]
  }
]